{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tpot\n",
        "!pip install deap\n",
        "!pip install auto-sklearn"
      ],
      "metadata": {
        "id": "hwvcCVes0meB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title private funcs\n",
        "\n",
        "def get_models_from_tpot(tpot):\n",
        "  result_list = []\n",
        "  counter = 0\n",
        "\n",
        "  for key, value in tpot.evaluated_individuals_.items():\n",
        "    if value['internal_cv_score'] ==  float('-inf'):\n",
        "      continue\n",
        "    deap_pipeline = creator.Individual.from_string(key, tpot._pset)\n",
        "    sklearn_pipeline = tpot._toolbox.compile(expr=deap_pipeline)\n",
        "    pipelin_model_name = sklearn_pipeline.steps[-1][1].__class__.__name__\n",
        "\n",
        "    set_param_recursive(sklearn_pipeline.steps, 'random_state', 42)\n",
        "\n",
        "    result_list.append((pipelin_model_name + '_' + str(counter),\n",
        "                          sklearn_pipeline # list(sklearn_pipeline.named_steps.values())[len(list(sklearn_pipeline.named_steps.values()))-1],\n",
        "                        )\n",
        "                          )\n",
        "    counter = counter + 1\n",
        "\n",
        "  return result_list\n",
        "\n",
        "def get_models_from_autosklearn(automl):\n",
        "  result_list = []\n",
        "  counter = 0\n",
        "\n",
        "  for model_id in automl.show_models().keys():\n",
        "    model = automl.show_models()[model_id]['sklearn_classifier']\n",
        "    if (hasattr(model, 'base_estimator_')):\n",
        "      result_list.append(( str(model.base_estimator_).split('(')[0] + '_' + str(counter),\n",
        "                          model.base_estimator_))\n",
        "    else:\n",
        "      result_list.append((str(model).split('(')[0] + '_' + str(counter), model))\n",
        "    counter = counter + 1\n",
        "  return result_list\n",
        "\n",
        "# вибір моделей\n",
        "def select_models(sklearn_models, count=None, isUniqModelsOnly=False):\n",
        "  if not isUniqModelsOnly:\n",
        "    return sklearn_models[:count] if count is not None else sklearn_models\n",
        "  result_list = []\n",
        "  for element in sklearn_models:\n",
        "    model_name =  element[0].split('_')[0]\n",
        "    if model_name not in [uniq_model_name[0].split('_')[0] for uniq_model_name in result_list]:\n",
        "      result_list.append(element)\n",
        "\n",
        "  return result_list[:count] if count is not None else result_list\n",
        "\n",
        "def eaSimpleCustom(population, toolbox, cxpb, mutpb, ngen, n_iter_no_change, stats=None,\n",
        "            halloffame=None, verbose=__debug__, greater_is_better=True):\n",
        "\n",
        "  logbook = tools.Logbook()\n",
        "  logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
        "\n",
        "  # Evaluate the individuals with an invalid fitness\n",
        "  invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "  fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "  for ind, fit in zip(invalid_ind, fitnesses):\n",
        "      ind.fitness.values = fit\n",
        "\n",
        "  if halloffame is not None:\n",
        "      halloffame.update(population)\n",
        "\n",
        "  record = stats.compile(population) if stats else {}\n",
        "  logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
        "  if verbose:\n",
        "    print(logbook.stream)\n",
        "\n",
        "  # Begin the generational process\n",
        "  for gen in range(1, ngen + 1):\n",
        "    # Select the next generation individuals\n",
        "    offspring = toolbox.select(population, len(population))\n",
        "\n",
        "    # Vary the pool of individuals\n",
        "    offspring = varAnd(offspring, toolbox, cxpb, mutpb)\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    # Update the hall of fame with the generated individuals\n",
        "    if halloffame is not None:\n",
        "      halloffame.update(offspring)\n",
        "\n",
        "    # Replace the current population by the offspring\n",
        "    population[:] = offspring\n",
        "\n",
        "    # population[:] = (population + offspring).sort()[:len(population)]\n",
        "\n",
        "    # Append the current generation statistics to the logbook\n",
        "    record = stats.compile(population) if stats else {}\n",
        "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
        "\n",
        "    if verbose:\n",
        "      print(logbook.stream)\n",
        "\n",
        "    if greater_is_better and n_iter_no_change != 0:\n",
        "      if earlyStoppingMax(logbook, n_iter_no_change):\n",
        "        break;\n",
        "    else:\n",
        "      if earlyStoppingMin(logbook, n_iter_no_change) and n_iter_no_change != 0:\n",
        "        break;\n",
        "\n",
        "  return population, logbook\n",
        "\n",
        "def earlyStoppingMax(logbook, n_iter_no_change):\n",
        "  gen_list, max_values=logbook.select('gen', 'max')\n",
        "  if len(max_values) < n_iter_no_change:\n",
        "    return False\n",
        "\n",
        "  max_elem_index = max_values.index(max(max_values))\n",
        "  if max_elem_index >= len(max_values) - n_iter_no_change:\n",
        "    return False # продовжити алгоритм\n",
        "\n",
        "  # if (max_values[-n_iter_no_change] < max_values[-n_iter_no_change + 1 : ]).any():\n",
        "  #   return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def earlyStoppingMin(logbook, n_iter_no_change):\n",
        "  gen_list, min_values=logbook.select('gen', 'min')\n",
        "  if len(min_values) < n_iter_no_change:\n",
        "    return False\n",
        "\n",
        "  min_elem_index = min_values.index(min(min_values))\n",
        "  if min_elem_index >= len(min_values) - n_iter_no_change:\n",
        "    return False\n",
        "\n",
        "  # if (min_values[-n_iter_no_change] > min_values[-n_iter_no_change + 1 : ]).any():\n",
        "  #   return False\n",
        "\n",
        "  return True\n",
        "\n",
        "\n",
        "def varAnd(population, toolbox, cxpb, mutpb):\n",
        "  offspring = [toolbox.clone(ind) for ind in population]\n",
        "\n",
        "  # Apply crossover and mutation on the offspring\n",
        "  for i in range(1, len(offspring), 2):\n",
        "      if random.random() < cxpb:\n",
        "          offspring[i - 1], offspring[i] = toolbox.mate(offspring[i - 1],\n",
        "                                                        offspring[i])\n",
        "          del offspring[i - 1].fitness.values, offspring[i].fitness.values\n",
        "\n",
        "  for i in range(len(offspring)):\n",
        "      if random.random() < mutpb:\n",
        "          offspring[i], = toolbox.mutate(offspring[i])\n",
        "          del offspring[i].fitness.values\n",
        "\n",
        "  return offspring"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T9JKjHIdxIvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title imports\n",
        "\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import autosklearn.classification\n",
        "import autosklearn.regression\n",
        "from sklearn.metrics import f1_score, r2_score\n",
        "from deap import base, creator, tools, algorithms\n",
        "from tpot import TPOTClassifier, TPOTRegressor\n",
        "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
        "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tpot.export_utils import generate_pipeline_code, expr_to_tree, set_param_recursive"
      ],
      "metadata": {
        "id": "sLk-abzewP9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQJVpmgRvPu_"
      },
      "outputs": [],
      "source": [
        "def gen_ensemble_builder_clf(X_train, X_test, y_train, y_test,\n",
        "                             scoring=accuracy_score, greater_is_better=True,\n",
        "                             use_tpot=True, use_autosklearn=True,\n",
        "                             TPOT_object=None, autosklearn_object=None,\n",
        "                             use_unique_type_models=False, models_count=None,\n",
        "                             population_size=50, cxpb=0.6, mutpb=0.3,\n",
        "                             indpb=0.4, ngen=500, verbose=False,\n",
        "                             cx_operator=tools.cxTwoPoint, mut_operator=tools.mutUniformInt,\n",
        "                             n_iter_no_change=20,\n",
        "                             sel_operator = lambda individuals, k: tools.selTournament(individuals, k, tournsize=3)):\n",
        "\n",
        "  print('i am working!')\n",
        "\n",
        "  scorer = make_scorer(score_func=scoring, greater_is_better=greater_is_better)\n",
        "\n",
        "  if not use_tpot and not use_autosklearn:\n",
        "    raise ValueError(\"At least one of use_tpot or use_autosklearn must be True.\")\n",
        "\n",
        "  if TPOT_object is not None and not isinstance(TPOT_object, TPOTClassifier):\n",
        "    raise TypeError(\"TPOT_object should be of type TPOTClassifier\")\n",
        "\n",
        "  if autosklearn_object is not None and not isinstance(autosklearn_object, AutoSklearnClassifier):\n",
        "    raise TypeError(\"autosklearn_object should be of type AutoSklearnClassifier\")\n",
        "\n",
        "  base_models = []\n",
        "\n",
        "  if use_tpot:\n",
        "    if TPOT_object is None:\n",
        "      TPOT_object = TPOTClassifier()\n",
        "      TPOT_object.fit(X_train, y_train)\n",
        "    else:\n",
        "      TPOT_object.fit(X_train, y_train)\n",
        "\n",
        "  base_models += get_models_from_tpot(TPOT_object)\n",
        "\n",
        "  if use_autosklearn:\n",
        "    if autosklearn_object is None:\n",
        "      autosklearn_object = autosklearn.classification.AutoSklearnClassifier()\n",
        "      autosklearn_object.fit(X_train, y_train)\n",
        "    else:\n",
        "      autosklearn_object.fit(X_train, y_train)\n",
        "\n",
        "    base_models += get_models_from_autosklearn(autosklearn_object)\n",
        "\n",
        "  base_models = select_models(base_models, models_count, use_unique_type_models)\n",
        "\n",
        "  # genetic algorithm\n",
        "  NBR_ITEMS=2\n",
        "  IND_INIT_SIZE=len(base_models)\n",
        "\n",
        "  def fitness_func(individual):\n",
        "    if all(i == 0 for i in individual):\n",
        "      return (0,)\n",
        "    estimators=[(t[0], t[1]) for i, t in enumerate(base_models) if individual[i]==1]\n",
        "\n",
        "    ensemble = VotingClassifier(estimators = estimators, voting='soft')\n",
        "    y_test_pred = ensemble.pred(X_test)\n",
        "\n",
        "    return (scorer(y_test, y_test_pred),)\n",
        "\n",
        "  hof = tools.HallOfFame(1)\n",
        "\n",
        "  s = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
        "  s.register(\"avg\", np.mean)\n",
        "  s.register(\"min\", np.min)\n",
        "  s.register(\"max\", np.max)\n",
        "\n",
        "  if greater_is_better:\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "  else:\n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "\n",
        "  toolbox = base.Toolbox()\n",
        "  toolbox.register(\"model_selector\", random.randrange, NBR_ITEMS)\n",
        "  toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.model_selector, IND_INIT_SIZE)\n",
        "  toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "  toolbox.register(\"evaluate\", fitness_func)\n",
        "  toolbox.register(\"mate\", cx_operator)\n",
        "  toolbox.register(\"mutate\", mut_operator, low=0, up=1, indpb=indpb)\n",
        "  toolbox.register(\"select\", sel_operator)\n",
        "\n",
        "  population = toolbox.population(n=population_size)\n",
        "\n",
        "  pop, log = eaSimpleCustom(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=ngen, n_iter_no_change=n_iter_no_change, verbose=verbose, halloffame=hof, stats=s)\n",
        "\n",
        "  best_individual = hof[0]\n",
        "\n",
        "  estimators=[(t[0], t[1]) for i, t in enumerate(base_models) if best_individual[i]==1]\n",
        "\n",
        "  result_ensemble = VotingClassifier(estimators = estimators, voting='soft').fit(X_test, y_test)\n",
        "\n",
        "  hof.clear()\n",
        "\n",
        "  return {\n",
        "          \"result ensemble\": result_ensemble,\n",
        "          \"TPOT\": TPOT_object,\n",
        "          \"autosklearn\": autosklearn_object\n",
        "         }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_ensemble_builder_regr(X_train, X_test, y_train, y_test,\n",
        "                             scoring=r2_score, greater_is_better=True,\n",
        "                             use_tpot=True, use_autosklearn=True,\n",
        "                             TPOT_object=None, autosklearn_object=None,\n",
        "                             use_unique_type_models=False, models_count=None,\n",
        "                             population_size=50, cxpb=0.6, mutpb=0.5,\n",
        "                             indpb=0.5, ngen=500, verbose=False,\n",
        "                             cx_operator=tools.cxTwoPoint, mut_operator=tools.mutUniformInt,\n",
        "                             n_iter_no_change=20,\n",
        "                             sel_operator = lambda individuals, k: tools.selTournament(individuals, k, tournsize=3)):\n",
        "\n",
        "  \"\"\"Fit an ensemble builder classifier using TPOT and auto-sklearn.\n",
        "\n",
        "    Fit an ensemble builder classifier that can utilize TPOT and auto-sklearn\n",
        "    for model optimization. This function optimizes machine learning models\n",
        "    and builds an ensemble out of them.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_train : array-like or sparse matrix of shape = [n_samples, n_features]\n",
        "        The training input samples.\n",
        "\n",
        "    X_test : array-like or sparse matrix of shape = [n_samples, n_features]\n",
        "        Test data input samples. Will be used to save test predictions for\n",
        "        all models. This allows to evaluate the performance of the ensemble\n",
        "        builder over time.\n",
        "\n",
        "    y_train : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
        "        The target classes for training.\n",
        "\n",
        "    y_test : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
        "        Test data target classes. Will be used to calculate the test error\n",
        "        of all models. This allows to evaluate the performance of the\n",
        "        ensemble builder over time.\n",
        "\n",
        "    scoring : callable, default=r2_score\n",
        "        The scoring function to use for evaluating the quality of the models.\n",
        "        This should be a function that takes two arrays as input (true and\n",
        "        predicted values) and returns a float. By default, it uses\n",
        "        `sklearn.metrics.r2_score`.\n",
        "\n",
        "    greater_is_better : bool, default=True\n",
        "        Whether the scoring function is maximizing (True) or minimizing (False).\n",
        "\n",
        "    use_tpot : bool, default=True\n",
        "        Whether to use TPOT for model optimization.\n",
        "        NOTE: at least one of use_tpot or use_autosklearn must be TRUE\n",
        "\n",
        "    use_autosklearn : bool, default=True\n",
        "        Whether to use auto-sklearn for model optimization.\n",
        "        NOTE: at least one of use_tpot or use_autosklearn must be TRUE\n",
        "\n",
        "    TPOT_object : TPOTRegressor object, default=None\n",
        "        A TPOTRegressor object to use for TPOT optimization. If None, a new\n",
        "        TPOTRegressor will be created.\n",
        "\n",
        "    autosklearn_object : AutoSklearnRegressor object, default=None\n",
        "        An AutoSklearnRegressor object to use for auto-sklearn optimization.\n",
        "        If None, a new AutoSklearnRegressor will be created.\n",
        "\n",
        "    use_unique_type_models : bool, default=False\n",
        "        Whether to only use unique model types in the ensemble. If True, each\n",
        "        model in the ensemble will be of a different type.\n",
        "\n",
        "    models_count : int, default=None\n",
        "        The number of models to include in the ensemble. If None, all models\n",
        "        will be included.\n",
        "\n",
        "    population_size : int, default=10\n",
        "        The number of individuals in the population.\n",
        "\n",
        "    cxpb : float, default=0.8\n",
        "        The probability of crossover for each pair of individuals.\n",
        "\n",
        "    mutpb : float, default=0.35\n",
        "        The probability of mutation for each individual.\n",
        "\n",
        "    indpb : float, default=0.5\n",
        "        The probability of each attribute to mutate for each individual.\n",
        "\n",
        "    ngen : int, default=100\n",
        "        The number of generations.\n",
        "\n",
        "    verbose : bool, default=False\n",
        "        Whether to print progress messages.\n",
        "\n",
        "    cx_operator : function, default=tools.cxTwoPoint\n",
        "        The crossover operator to use.\n",
        "\n",
        "    mut_operator : function, default=tools.mutUniformInt\n",
        "        The mutation operator to use.\n",
        "\n",
        "    n_iter_no_change : int, default=20\n",
        "        Maximum number of epochs the fitness function does not come better.\n",
        "        Set value to 0 to pass through all epochs.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    result : dict\n",
        "        A dictionary containing the following items:\n",
        "        - \"result_ensemble\": Fitted ensemble builder classifier.\n",
        "        - \"TPOT\": Fitted TPOTRegressor object used for TPOT optimization.\n",
        "        - \"autosklearn\": Fitted AutoSklearnRegressor object used for auto-sklearn optimization\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  scorer = make_scorer(scoring, greater_is_better)\n",
        "\n",
        "  if not use_tpot and not use_autosklearn:\n",
        "    raise ValueError(\"At least one of use_tpot or use_autosklearn must be True.\")\n",
        "\n",
        "  if TPOT_object is not None and not isinstance(TPOT_object, TPOTRegressor):\n",
        "    raise TypeError(\"TPOT_object should be of type TPOTRegressor\")\n",
        "\n",
        "  if autosklearn_object is not None and not isinstance(autosklearn_object, AutoSklearnRegressor):\n",
        "    raise TypeError(\"autosklearn_object should be of type AutoSklearnRegressor\")\n",
        "\n",
        "  base_models = []\n",
        "\n",
        "  if use_tpot:\n",
        "    if TPOT_object is None:\n",
        "      TPOT_object = TPOTRegressor()\n",
        "      TPOT_object.fit(X_train, y_train)\n",
        "    else:\n",
        "      TPOT_object.fit(X_train, y_train)\n",
        "\n",
        "    base_models += get_models_from_tpot(TPOT_object)\n",
        "\n",
        "  if use_autosklearn:\n",
        "    if autosklearn_object is None:\n",
        "      autosklearn_object = autosklearn.classification.AutoSklearnRegressor()\n",
        "      autosklearn_object.fit(X_train, y_train)\n",
        "    else:\n",
        "      autosklearn_object.fit(X_train, y_train)\n",
        "\n",
        "    base_models += get_models_from_autosklearn(autosklearn_object)\n",
        "\n",
        "  base_models = select_models(base_models, models_count, use_unique_type_models)\n",
        "\n",
        "  # Genetic algorithm\n",
        "  cv=5\n",
        "  NBR_ITEMS=2\n",
        "  IND_INIT_SIZE=len(base_models)\n",
        "\n",
        "  def fitness_func(individual):\n",
        "    if all(i == 0 for i in individual):\n",
        "      return (0,)\n",
        "    estimators=[(t[0], t[1]) for i, t in enumerate(input_models) if individual[i]==1]\n",
        "\n",
        "    ensemble = VotingClassifier(estimators = estimators, voting='soft')\n",
        "    y_test_pred = ensemble.pred(X_test)\n",
        "\n",
        "    return (scorer(y_test, y_test_pred),)\n",
        "\n",
        "  hof = tools.HallOfFame(1)\n",
        "\n",
        "  s = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
        "  s.register(\"avg\", np.mean)\n",
        "  s.register(\"min\", np.min)\n",
        "  s.register(\"max\", np.max)\n",
        "\n",
        "  if greater_is_better:\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "  else:\n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "\n",
        "  toolbox = base.Toolbox()\n",
        "  toolbox.register(\"model_selector\", random.randrange, NBR_ITEMS)\n",
        "  toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.model_selector, IND_INIT_SIZE)\n",
        "  toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "  toolbox.register(\"evaluate\", fitness_func)\n",
        "  toolbox.register(\"mate\", cx_operator)\n",
        "  toolbox.register(\"mutate\", mut_operator, low=0, up=1, indpb=indpb)\n",
        "  toolbox.register(\"select\", sel_operator)\n",
        "\n",
        "  population = toolbox.population(n=population_size)\n",
        "\n",
        "  pop, log = eaSimpleCustom(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=ngen, n_iter_no_change=n_iter_no_change, verbose=verbose, halloffame=hof, stats=s)\n",
        "\n",
        "  best_individual = hof[0]\n",
        "\n",
        "  estimators=[(t[0], t[1]) for i, t in enumerate(input_models) if best_individual[i]==1]\n",
        "\n",
        "  result_ensemble = VotingClassifier(estimators = estimators, voting='soft').fit(X_test, y_test)\n",
        "\n",
        "  hof.clear()\n",
        "\n",
        "  return {\n",
        "          \"result ensemble\": result_ensemble,\n",
        "          \"TPOT\": TPOT_object,\n",
        "          \"autosklearn\": autosklearn_object\n",
        "         }"
      ],
      "metadata": {
        "id": "4NqTU7qKNh55"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}